{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc756742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Base class for a dataset\n",
    "\"\"\"\n",
    "import abc\n",
    "import logging\n",
    "from inspect import signature\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296b2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(metaclass=abc.ABCMeta):\n",
    "    \"\"\"BaseDataset\n",
    "    Parameters required for all datasets\n",
    "    parameters\n",
    "    ----------\n",
    "    subjects: List of int\n",
    "        List of subject number (or tuple or numpy array)\n",
    "    sessions_per_subject: int\n",
    "        Number of sessions per subject (if varying, take minimum)\n",
    "    events: dict of strings\n",
    "        String codes for events matched with labels in the stim channel.\n",
    "        Currently imagery codes codes can include:\n",
    "        - target\n",
    "        - NonTarget\n",
    "        - Consistent\n",
    "        - Inconsistent\n",
    "    code: string\n",
    "        Unique identifier for dataset, used in all plots\n",
    "    interval: list with 2 entries\n",
    "        Imagery interval as defined in the dataset description\n",
    "    paradigm: ['p300','N400']\n",
    "        Defines what sort of dataset this is\n",
    "    doi: DOI for dataset, optional (for now)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        subjects,\n",
    "        sessions_per_subject,\n",
    "        events,\n",
    "        code,\n",
    "        interval,\n",
    "        paradigm,\n",
    "        doi=None,\n",
    "        unit_factor=1e6,\n",
    "    ):\n",
    "        try:\n",
    "            _ = iter(subjects)\n",
    "        except TypeError:\n",
    "            raise ValueError(\"subjects must be a iterable, like a list\") from None\n",
    "\n",
    "        self.subject_list = subjects\n",
    "        self.n_sessions = sessions_per_subject\n",
    "        self.event_id = events\n",
    "        self.code = code\n",
    "        self.interval = interval\n",
    "        self.paradigm = paradigm\n",
    "        self.doi = doi\n",
    "        self.unit_factor = unit_factor\n",
    "\n",
    "    def get_data(self, subjects=None):\n",
    "        \"\"\"Return the data correspoonding to a list of subjects.\n",
    "        The returned data is a dictionary with the folowing structure::\n",
    "            data = {'subject_id' :\n",
    "                        {'session_id':\n",
    "                            {'run_id': raw}\n",
    "                        }\n",
    "                    }\n",
    "        subjects are on top, then we have sessions, then runs.\n",
    "        A sessions is a recording done in a single day, without removing the\n",
    "        EEG cap. A session is constitued of at least one run. A run is a single\n",
    "        contigous recording. Some dataset break session in multiple runs.\n",
    "        Parameters\n",
    "        ----------\n",
    "        subjects: List of int\n",
    "            List of subject number\n",
    "        Returns\n",
    "        -------\n",
    "        data: Dict\n",
    "            dict containing the raw data\n",
    "        \"\"\"\n",
    "        if subjects is None:\n",
    "            subjects = self.subject_list\n",
    "\n",
    "        if not isinstance(subjects, list):\n",
    "            raise (ValueError(\"subjects must be a list\"))\n",
    "\n",
    "        data = dict()\n",
    "        for subject in subjects:\n",
    "            if subject not in self.subject_list:\n",
    "                raise ValueError(\"Invalid subject {:d} given\".format(subject))\n",
    "            data[subject] = self._get_single_subject_data(subject)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def download(\n",
    "        self,\n",
    "        subject_list=None,\n",
    "        path=None,\n",
    "        force_update=False,\n",
    "        update_path=None,\n",
    "        accept=False,\n",
    "        verbose=None,\n",
    "    ):\n",
    "        \"\"\"Download all data from the dataset.\n",
    "        This function is only usefull to download all the dataset at once.\n",
    "        Parameters\n",
    "        ----------\n",
    "        subject_list : list of int | None\n",
    "            List of subjects id to download, if None all subjects\n",
    "            are downloaded.\n",
    "        path : None | str\n",
    "            Location of where to look for the data storing location.\n",
    "            If None, the environment variable or config parameter\n",
    "            ``MNE_DATASETS_(dataset)_PATH`` is used. If it doesn't exist, the\n",
    "            \"~/mne_data\" directory is used. If the dataset\n",
    "            is not found under the given path, the data\n",
    "            will be automatically downloaded to the specified folder.\n",
    "        force_update : bool\n",
    "            Force update of the dataset even if a local copy exists.\n",
    "        update_path : bool | None\n",
    "            If True, set the MNE_DATASETS_(dataset)_PATH in mne-python\n",
    "            config to the given path. If None, the user is prompted.\n",
    "        accept: bool\n",
    "            Accept licence term to download the data, if any. Default: False\n",
    "        verbose : bool, str, int, or None\n",
    "            If not None, override default verbose level\n",
    "            (see :func:`mne.verbose`).\n",
    "        \"\"\"\n",
    "        if subject_list is None:\n",
    "            subject_list = self.subject_list\n",
    "        for subject in subject_list:\n",
    "            # check if accept is needed\n",
    "            sig = signature(self.data_path)\n",
    "            if \"accept\" in [str(p) for p in sig.parameters]:\n",
    "                self.data_path(\n",
    "                    subject=subject,\n",
    "                    path=path,\n",
    "                    force_update=force_update,\n",
    "                    update_path=update_path,\n",
    "                    verbose=verbose,\n",
    "                    accept=accept,\n",
    "                )\n",
    "            else:\n",
    "                self.data_path(\n",
    "                    subject=subject,\n",
    "                    path=path,\n",
    "                    force_update=force_update,\n",
    "                    update_path=update_path,\n",
    "                    verbose=verbose,\n",
    "                )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _get_single_subject_data(self, subject):\n",
    "        \"\"\"Return the data of a single subject.\n",
    "        The returned data is a dictionary with the folowing structure\n",
    "        data = {'session_id':\n",
    "                    {'run_id': raw}\n",
    "                }\n",
    "        parameters\n",
    "        ----------\n",
    "        subject: int\n",
    "            subject number\n",
    "        returns\n",
    "        -------\n",
    "        data: Dict\n",
    "            dict containing the raw data\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def data_path(\n",
    "        self, subject, path=None, force_update=False, update_path=None, verbose=None\n",
    "    ):\n",
    "        \"\"\"Get path to local copy of a subject data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        subject : int\n",
    "            Number of subject to use\n",
    "        path : None | str\n",
    "            Location of where to look for the data storing location.\n",
    "            If None, the environment variable or config parameter\n",
    "            ``MNE_DATASETS_(dataset)_PATH`` is used. If it doesn't exist, the\n",
    "            \"~/mne_data\" directory is used. If the dataset\n",
    "            is not found under the given path, the data\n",
    "            will be automatically downloaded to the specified folder.\n",
    "        force_update : bool\n",
    "            Force update of the dataset even if a local copy exists.\n",
    "        update_path : bool | None **Deprecated**\n",
    "            If True, set the MNE_DATASETS_(dataset)_PATH in mne-python\n",
    "            config to the given path. If None, the user is prompted.\n",
    "        verbose : bool, str, int, or None\n",
    "            If not None, override default verbose level\n",
    "            (see :func:`mne.verbose`).\n",
    "        Returns\n",
    "        -------\n",
    "        path : list of str\n",
    "            Local path to the given data file. This path is contained inside a\n",
    "            list of length one, for compatibility.\n",
    "        \"\"\"  \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad618872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:master_thesis]",
   "language": "python",
   "name": "conda-env-master_thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
